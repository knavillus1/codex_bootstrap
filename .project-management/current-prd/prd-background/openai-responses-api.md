# OpenAI Responses APIÂ GuideÂ 

> **In a nutshell:**
> The **Responses API** accepts an array of chatâ€‘style *messages* (`input`).  Text history is simply appended to this array, and images can be referenced by URL *or* embedded as a base64 dataâ€‘URI.  Below youâ€™ll learn the exact message format, see code for both Python and JavaScript, and walk through an endâ€‘toâ€‘end example.

---

## 1Â Â·Â Message & History Format Recap

| Key       | Required? | Typical values                      | Notes                                                  |
| --------- | --------- | ----------------------------------- | ------------------------------------------------------ |
| `role`    | âœ”         | `"user"`,Â `"assistant"`,Â `"system"` | Same set you already know from Chat Completions.       |
| `content` | âœ”         | *String* **or** list of parts       | Image parts use `{type:"input_image", image_url:"â€¦"}`. |

*Uploading history* is nothing more than pushing each earlier turn into the `input` array in chronological order.

---

## 2Â Â·Â Including Images

### 2.1Â External URL (quickest)

```json
{
  "type": "input_image",
  "image_url": "https://example.com/photo.jpg"
}
```

OpenAI fetches the image for you.

### 2.2Â Inâ€‘lined base64 (no public hosting required)

```json
{
  "type": "input_image",
  "image_url": "data:image/jpeg;base64,/9j/4AAQSkZJRgABAQ..."
}
```

Here `image_url` is a **data URI**: the literal string `data:<mime>;base64,<bytes>`.

---

## 3Â Â·Â Base64â€‘encoding Recipes

### 3.1Â Browser JavaScript (clientâ€‘side)

```js
const fileInput = document.querySelector("input[type=file]");
fileInput.onchange = () => {
  const file = fileInput.files[0];
  const reader = new FileReader();
  reader.onload = () => {
    const dataUri = reader.result; // "data:image/png;base64,iVBORw0K..."
    // use dataUri in your API request
  };
  reader.readAsDataURL(file);      // converts to base64 data URI
};
```

### 3.2Â NodeÂ /Â server JavaScript

```js
import { readFileSync } from "fs";
const imgBytes = readFileSync("photo.jpg");
const dataUri = `data:image/jpeg;base64,${imgBytes.toString("base64")}`;
```

### 3.3Â Python

```python
import base64, mimetypes, pathlib

def to_data_uri(path: str) -> str:
    mime, _ = mimetypes.guess_type(path)
    with open(path, "rb") as f:
        encoded = base64.b64encode(f.read()).decode("ascii")
    return f"data:{mime or 'image/png'};base64,{encoded}"
```

---

## 4Â Â·Â Full Python Example (textÂ + historyÂ + base64 image)

```python
from openai import OpenAI
import base64, mimetypes

client = OpenAI()

def to_data_uri(path):
    mime, _ = mimetypes.guess_type(path)
    with open(path, "rb") as f:
        b64 = base64.b64encode(f.read()).decode("ascii")
    return f"data:{mime or 'image/jpeg'};base64,{b64}"

history = [
    {"role": "system", "content": "You are a sports analyst."},
    {"role": "user",   "content": "What two teams are playing in this photo?"},
]

history.append({
    "role": "user",
    "content": [
        {
            "type": "input_image",
            "image_url": to_data_uri("lebron.jpg")
        }
    ]
})

resp = client.responses.create(
    model="gpt-4.1",
    input=history
)

print(resp.output_text)
```

Everythingâ€”history **and** inline imageâ€”travels inside the single `input` array.

---

## 5Â Â·Â Goodâ€‘practice Checklist

* **Prefer URLs** for large or alreadyâ€‘hosted images; base64 inflates payloads \~33â€¯%.
* Keep the whole conversation under the modelâ€™s context limit; truncate or summarise old turns.
* Verify `Contentâ€‘Type` in your data URI matches the actual file (e.g. `image/png`).
* In browsers, watch out for **CORS** if you fetch remote images before reâ€‘encoding.
* For production, consider `stream=True` to reduce tail latency.

---

Happy shipping!Â ðŸŽ‰
